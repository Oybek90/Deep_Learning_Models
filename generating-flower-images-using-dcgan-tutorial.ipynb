{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Step 1: Import all required functions and libraries","metadata":{}},{"cell_type":"code","source":"# Import all required functions and libraries\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import (Conv2D, Dense, BatchNormalization, \n                                     BatchNormalization, Flatten,  Reshape,\n                                     Conv2DTranspose)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:08:50.105544Z","iopub.execute_input":"2023-06-13T05:08:50.106269Z","iopub.status.idle":"2023-06-13T05:09:08.747977Z","shell.execute_reply.started":"2023-06-13T05:08:50.106213Z","shell.execute_reply":"2023-06-13T05:09:08.746906Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 2: Build the discriminator","metadata":{}},{"cell_type":"code","source":"def discriminator_model():\n    \n    # Instantiates the discriminator using\n    # the Keras sequential API\n    discriminator = Sequential(name=\"Discriminator\")\n\n    # Adds a convolutional layer to the discriminator\n    # (from 256 × 256 × 3 into 128 × 128 × 32 tensor)\n    discriminator.add(Conv2D(32, kernel_size=3, name=\"Conv_1\",\n                           strides=2, activation='leaky_relu',\n                           input_shape=(256, 256, 3), padding=\"same\"))\n\n    # Adds a second convolutional layer to the discriminator\n    # (from 128 × 128 × 32 into 64 × 64 × 64 tensor)\n    discriminator.add(Conv2D(64, kernel_size=3, strides=2, name=\"Conv_2\",\n                           activation='leaky_relu', padding=\"same\"))\n\n    # Adds a batch normalization layer for stable training\n    discriminator.add(BatchNormalization(name=\"BN_1\"))\n\n    # Adds a third convolutional layer to the discriminator\n    # (from 64 × 64 × 64 into 32 × 32 × 128 tensor)\n    discriminator.add(Conv2D(128, kernel_size=3, strides=2, name=\"Conv_3\",\n                           activation='leaky_relu', padding=\"same\"))\n\n    # Adds another batch normalization layer for stable training\n    discriminator.add(BatchNormalization(name=\"BN_2\"))\n\n    # Adds a fourth convolutional layer to the discriminator\n    # (from 32 × 32 × 128 into 16 × 16 × 256 tensor)\n    discriminator.add(Conv2D(256, kernel_size=3, strides=2, name=\"Conv_4\",\n                           activation='leaky_relu', padding=\"same\"))\n\n    # Adds another batch normalization layer for stable training\n    discriminator.add(BatchNormalization(name=\"BN_3\"))\n\n    # Adds a fifth convolutional layer to the discriminator\n    # (from 16 × 16 × 256 into 8 × 8 × 512 tensor)\n    discriminator.add(Conv2D(512, kernel_size=3, strides=2, name=\"Conv_5\",\n                           activation='leaky_relu', padding=\"same\"))\n\n    # Adds another batch normalization layer for stable training\n    discriminator.add(BatchNormalization(name=\"BN_4\"))\n\n    # Flattens the network\n    # (from 8 × 8 × 512 into (32768, ) 1D tensor)\n    discriminator.add(Flatten())\n\n    # Adds the output dense layer with sigmoid activation\n    discriminator.add(Dense(1, activation='sigmoid'))\n\n    # Prints the discriminator summary\n    discriminator.summary()\n\n    return discriminator","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:14:09.991115Z","iopub.execute_input":"2023-06-13T05:14:09.992200Z","iopub.status.idle":"2023-06-13T05:14:10.005545Z","shell.execute_reply.started":"2023-06-13T05:14:09.992162Z","shell.execute_reply":"2023-06-13T05:14:10.004356Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"discriminator_model()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:14:24.912208Z","iopub.execute_input":"2023-06-13T05:14:24.912592Z","iopub.status.idle":"2023-06-13T05:14:30.983980Z","shell.execute_reply.started":"2023-06-13T05:14:24.912559Z","shell.execute_reply":"2023-06-13T05:14:30.983087Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model: \"Discriminator\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Conv_1 (Conv2D)             (None, 128, 128, 32)      896       \n                                                                 \n Conv_2 (Conv2D)             (None, 64, 64, 64)        18496     \n                                                                 \n BN_1 (BatchNormalization)   (None, 64, 64, 64)        256       \n                                                                 \n Conv_3 (Conv2D)             (None, 32, 32, 128)       73856     \n                                                                 \n BN_2 (BatchNormalization)   (None, 32, 32, 128)       512       \n                                                                 \n Conv_4 (Conv2D)             (None, 16, 16, 256)       295168    \n                                                                 \n BN_3 (BatchNormalization)   (None, 16, 16, 256)       1024      \n                                                                 \n Conv_5 (Conv2D)             (None, 8, 8, 512)         1180160   \n                                                                 \n BN_4 (BatchNormalization)   (None, 8, 8, 512)         2048      \n                                                                 \n flatten (Flatten)           (None, 32768)             0         \n                                                                 \n dense (Dense)               (None, 1)                 32769     \n                                                                 \n=================================================================\nTotal params: 1,605,185\nTrainable params: 1,603,265\nNon-trainable params: 1,920\n_________________________________________________________________\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<keras.engine.sequential.Sequential at 0x78e1478e78b0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Step 3: Build the generator","metadata":{}},{"cell_type":"code","source":"def generator_model():\n\n    # Instantiates the generator using\n    # the Keras sequential API\n    generator = Sequential(name=\"Generator\")\n\n    # Adds a dense layer that has a number of neurons = 128 × 32 × 32\n    # Input shape is 9 which is equal to the size of the noise vector\n    generator.add(Dense(128 * 32 * 32, input_shape=(9, )))\n\n    # Reshapes the image dimensions to 32 × 32 × 128\n    generator.add(Reshape((32, 32, 128)))\n\n    # Adds an upsampling layer to double the image size \n    # from 32 x 32 to 64 x 64\n    generator.add(Conv2DTranspose(64, kernel_size=3, strides=2, name=\"ConvTr_1\",\n                                padding='same', activation=\"relu\"))\n\n    # Adds a batch normalization layer for stable training\n    generator.add(BatchNormalization(name=\"BN_1\"))\n\n    # Adds a second upsampling layer to double the image size \n    # from 64 x 64 to 128 x 128\n    generator.add(Conv2DTranspose(32, kernel_size=3, strides=2, name=\"ConvTr_2\",\n                                padding='same', activation=\"relu\"))\n\n    # Adds another batch normalization layer for stable training\n    generator.add(BatchNormalization(name=\"BN_2\"))\n\n    # Adds a third upsampling layer with strides=1\n    # This time, image size will not change\n    # Tensor shape will change from 128 x 128 x 32 to 128 x 128 x 16\n    generator.add(Conv2DTranspose(16, kernel_size=3, strides=1, name=\"ConvTr_3\",\n                                padding='same', activation=\"relu\"))\n\n    # Adds another batch normalization layer for stable training\n    generator.add(BatchNormalization(name=\"BN_3\"))\n\n    # Adds a fourth upsampling layer to double the image size \n    # from 128 x 128 to 256 x 256 which is the original shape.\n\n    # We don't need to add upsampling layers again becasue\n    # the image size of 256 x 256  is equal to the original image size.\n\n    # At the final layer, we do not apply batch normalization and,\n    # instead of ReLU, we use the tanh activation.\n\n    # The number of filters in the final layer is equal to the\n    # number of color channels\n    generator.add(Conv2DTranspose(3, kernel_size=3, strides=2, name=\"ConvTr_4\",\n                                padding='same', activation=\"tanh\"))\n\n    # Prints the generator summary\n    generator.summary()\n\n    return generator","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:22:22.241421Z","iopub.execute_input":"2023-06-13T05:22:22.241849Z","iopub.status.idle":"2023-06-13T05:22:22.260265Z","shell.execute_reply.started":"2023-06-13T05:22:22.241799Z","shell.execute_reply":"2023-06-13T05:22:22.258451Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"generator_model()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:22:31.338321Z","iopub.execute_input":"2023-06-13T05:22:31.338672Z","iopub.status.idle":"2023-06-13T05:22:31.520988Z","shell.execute_reply.started":"2023-06-13T05:22:31.338643Z","shell.execute_reply":"2023-06-13T05:22:31.520173Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"Generator\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_1 (Dense)             (None, 131072)            1310720   \n                                                                 \n reshape (Reshape)           (None, 32, 32, 128)       0         \n                                                                 \n ConvTr_1 (Conv2DTranspose)  (None, 64, 64, 64)        73792     \n                                                                 \n BN_1 (BatchNormalization)   (None, 64, 64, 64)        256       \n                                                                 \n ConvTr_2 (Conv2DTranspose)  (None, 128, 128, 32)      18464     \n                                                                 \n BN_2 (BatchNormalization)   (None, 128, 128, 32)      128       \n                                                                 \n ConvTr_3 (Conv2DTranspose)  (None, 128, 128, 16)      4624      \n                                                                 \n BN_3 (BatchNormalization)   (None, 128, 128, 16)      64        \n                                                                 \n ConvTr_4 (Conv2DTranspose)  (None, 256, 256, 3)       435       \n                                                                 \n=================================================================\nTotal params: 1,408,483\nTrainable params: 1,408,259\nNon-trainable params: 224\n_________________________________________________________________\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<keras.engine.sequential.Sequential at 0x78e147ad90c0>"},"metadata":{}}]},{"cell_type":"code","source":"discriminator = discriminator_model()\ngenerator = generator_model()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:23:20.067730Z","iopub.execute_input":"2023-06-13T05:23:20.068453Z","iopub.status.idle":"2023-06-13T05:23:20.406776Z","shell.execute_reply.started":"2023-06-13T05:23:20.068415Z","shell.execute_reply":"2023-06-13T05:23:20.406006Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"Discriminator\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Conv_1 (Conv2D)             (None, 128, 128, 32)      896       \n                                                                 \n Conv_2 (Conv2D)             (None, 64, 64, 64)        18496     \n                                                                 \n BN_1 (BatchNormalization)   (None, 64, 64, 64)        256       \n                                                                 \n Conv_3 (Conv2D)             (None, 32, 32, 128)       73856     \n                                                                 \n BN_2 (BatchNormalization)   (None, 32, 32, 128)       512       \n                                                                 \n Conv_4 (Conv2D)             (None, 16, 16, 256)       295168    \n                                                                 \n BN_3 (BatchNormalization)   (None, 16, 16, 256)       1024      \n                                                                 \n Conv_5 (Conv2D)             (None, 8, 8, 512)         1180160   \n                                                                 \n BN_4 (BatchNormalization)   (None, 8, 8, 512)         2048      \n                                                                 \n flatten_1 (Flatten)         (None, 32768)             0         \n                                                                 \n dense_2 (Dense)             (None, 1)                 32769     \n                                                                 \n=================================================================\nTotal params: 1,605,185\nTrainable params: 1,603,265\nNon-trainable params: 1,920\n_________________________________________________________________\nModel: \"Generator\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_3 (Dense)             (None, 131072)            1310720   \n                                                                 \n reshape_1 (Reshape)         (None, 32, 32, 128)       0         \n                                                                 \n ConvTr_1 (Conv2DTranspose)  (None, 64, 64, 64)        73792     \n                                                                 \n BN_1 (BatchNormalization)   (None, 64, 64, 64)        256       \n                                                                 \n ConvTr_2 (Conv2DTranspose)  (None, 128, 128, 32)      18464     \n                                                                 \n BN_2 (BatchNormalization)   (None, 128, 128, 32)      128       \n                                                                 \n ConvTr_3 (Conv2DTranspose)  (None, 128, 128, 16)      4624      \n                                                                 \n BN_3 (BatchNormalization)   (None, 128, 128, 16)      64        \n                                                                 \n ConvTr_4 (Conv2DTranspose)  (None, 256, 256, 3)       435       \n                                                                 \n=================================================================\nTotal params: 1,408,483\nTrainable params: 1,408,259\nNon-trainable params: 224\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 4: Compile the discriminator","metadata":{}},{"cell_type":"code","source":"# Compiles the discriminator\ndiscriminator.compile(loss='binary_crossentropy', \n                      optimizer=Adam(learning_rate=0.001), \n                      metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:24:21.251468Z","iopub.execute_input":"2023-06-13T05:24:21.251808Z","iopub.status.idle":"2023-06-13T05:24:21.276762Z","shell.execute_reply.started":"2023-06-13T05:24:21.251777Z","shell.execute_reply":"2023-06-13T05:24:21.275701Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Step 5: Build the GAN (combined) model","metadata":{}},{"cell_type":"code","source":"# Combined model = Complete GAN model\ndef GAN_model(generator, discriminator):\n\n    # Instantiates the GAN model using\n    # the Keras sequential API\n    GAN = Sequential(name=\"GAN\")\n\n    # Freezes the weights of the discriminator to avoid updating \n    # the discriminator’s weights during generator training\n    discriminator.trainable = False\n\n    # Combines both generator and discriminator\n    GAN.add(generator)\n    GAN.add(discriminator)\n\n    return GAN","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:26:30.540793Z","iopub.execute_input":"2023-06-13T05:26:30.541171Z","iopub.status.idle":"2023-06-13T05:26:30.547390Z","shell.execute_reply.started":"2023-06-13T05:26:30.541142Z","shell.execute_reply":"2023-06-13T05:26:30.545884Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"GAN = GAN_model(generator, discriminator)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:51.108650Z","iopub.execute_input":"2023-06-13T05:27:51.109742Z","iopub.status.idle":"2023-06-13T05:27:51.242512Z","shell.execute_reply.started":"2023-06-13T05:27:51.109697Z","shell.execute_reply":"2023-06-13T05:27:51.241523Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Step 6: Compile the GAN (combined) model","metadata":{}},{"cell_type":"code","source":"# Compiles GAN (combined) model\nGAN.compile(loss='binary_crossentropy', \n            optimizer=Adam(learning_rate=0.001))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:29:50.836947Z","iopub.execute_input":"2023-06-13T05:29:50.837880Z","iopub.status.idle":"2023-06-13T05:29:50.852643Z","shell.execute_reply.started":"2023-06-13T05:29:50.837815Z","shell.execute_reply":"2023-06-13T05:29:50.851382Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Step 7: Define the train function","metadata":{}},{"cell_type":"code","source":"def train(epochs, batch_size=128, save_interval=50):\n\n    # Adversarial ground truths\n\n    # Labels (1s) for real images:\n    real = np.ones((batch_size, 1))\n    # Labels (0s) for fake images:\n    fake = np.zeros((batch_size, 1))\n\n    for epoch in range(epochs):\n\n        # Gets a random batch of real images\n        index = np.random.randint(0, 3670 , batch_size)\n        images = flowers_train[index]\n\n        # Generates a batch of fake images\n        noise = np.random.normal(0, 1, (batch_size, 9))\n        gen_images = generator.predict(noise)\n\n        # Trains the discriminator \n        # Real images are classified as 1s and \n        # generated images are classified as 0s)\n        d_loss_real = discriminator.train_on_batch(images, real)\n        d_loss_fake = discriminator.train_on_batch(gen_images, fake)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n        # Train the combined model (generator)\n        g_loss = GAN.train_on_batch(noise, real)\n\n        # Outputs generated image samples at save_interval\n        if epoch % save_interval == 0:\n          plot_generated_images(generator)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:22:40.324253Z","iopub.execute_input":"2023-06-13T06:22:40.324653Z","iopub.status.idle":"2023-06-13T06:22:40.334635Z","shell.execute_reply.started":"2023-06-13T06:22:40.324620Z","shell.execute_reply":"2023-06-13T06:22:40.333515Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def plot_generated_images(generator, image_grid_rows=3, image_grid_columns=3):\n\n    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, 9))\n    generated_images = generator.predict(z)\n    generated_images = 0.5 * generated_images + 0.5\n    fig, ax = plt.subplots(image_grid_rows, image_grid_columns,\n                         figsize=(3, 3), sharey=True, sharex=True)\n\n    cnt = 0\n    for i in range(image_grid_rows):\n        for j in range(image_grid_columns):\n            ax[i, j].imshow(generated_images[cnt, :, :, 0])\n            ax[i, j].axis('off')\n            cnt += 1","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:23:43.974413Z","iopub.execute_input":"2023-06-13T06:23:43.974775Z","iopub.status.idle":"2023-06-13T06:23:43.983266Z","shell.execute_reply.started":"2023-06-13T06:23:43.974744Z","shell.execute_reply":"2023-06-13T06:23:43.982175Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Step 8: Load and preprocess the flowers dataset","metadata":{}},{"cell_type":"code","source":"# Load the flowers dataset using TFDS library\ndataset, info = tfds.load('tf_flowers', split='train', with_info=True)\n\n# Define a function to preprocess data\ndef preprocess(example):\n    image = example['image']\n    # Resize the image to 256 x 256\n    image = tf.image.resize(image, [256, 256])\n    # Convert the pixel values to [0, 1] to normalize data\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# Apply preprocess function to each individual image and convert\n# all images into a numpy array\nimages = []\nfor example in dataset:\n    image = preprocess(example)\n    images.append(image.numpy())\nflowers_train = np.array(images)\n\n# Print the shape of the array\nprint(flowers_train.shape) # (total_images, img_size, img_size, 3)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:25:40.302475Z","iopub.execute_input":"2023-06-13T06:25:40.303556Z","iopub.status.idle":"2023-06-13T06:26:05.322150Z","shell.execute_reply.started":"2023-06-13T06:25:40.303507Z","shell.execute_reply":"2023-06-13T06:26:05.321109Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\u001b[1mDownloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.1...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"585da4b833984a26a53f87ec502708fb"}},"metadata":{}},{"name":"stdout","text":"\u001b[1mDataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n(3670, 256, 256, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 9: Train the GAN model","metadata":{}},{"cell_type":"code","source":"train(epochs=8000, batch_size=32, save_interval=50)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:26:46.878806Z","iopub.execute_input":"2023-06-13T06:26:46.880080Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 13s 13s/step\n1/1 [==============================] - 1s 728ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 67ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 38ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 48ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 37ms/step\n1/1 [==============================] - 0s 34ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 32ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 38ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 32ms/step\n1/1 [==============================] - 0s 29ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 47ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 46ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 38ms/step\n1/1 [==============================] - 0s 30ms/step\n1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 18ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}