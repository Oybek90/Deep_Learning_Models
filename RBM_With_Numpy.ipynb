{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "\n",
    "class RBM:\n",
    "    \"\"\"Restricted Boltzmann Machine.\"\"\"\n",
    "\n",
    "    def __init__(self, n_hidden=2, m_observe=784):\n",
    "        \"\"\"Initialize model.\n",
    "        Args:\n",
    "            n_hidden: int, the number of hidden units\n",
    "            m_observe: int, the number of visible units\n",
    "        \"\"\"\n",
    "        self.n_hidden = n_hidden\n",
    "        self.m_visible = m_observe\n",
    "\n",
    "        self.visible = None\n",
    "        self.weight = np.random.rand(self.m_visible, self.n_hidden)  # [m, n]\n",
    "        self.a = np.random.rand(self.m_visible, 1)  # [m, 1]\n",
    "        self.b = np.random.rand(self.n_hidden, 1)  # [n, 1]\n",
    "\n",
    "        self.alpha = 0.01\n",
    "        self.avg_energy_record = []\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def train(self, data, epochs=2):\n",
    "        \"\"\"train the RBM\n",
    "        Args:\n",
    "            data: numpy ndarray of shape [N, m], representing N sample with m visible units\n",
    "            epochs: int, the total number of epochs in training\n",
    "        \"\"\"\n",
    "\n",
    "        self.avg_energy_record.clear()\n",
    "        self.visible = data.reshape(-1, self.m_visible)\n",
    "        self.__contrastive_divergence(self.visible, epochs)\n",
    "\n",
    "        print(\"training finished\")\n",
    "\n",
    "    def __forward(self, v):\n",
    "        h_dist = self.sigmoid(\n",
    "            np.matmul(np.transpose(self.weight), v) + self.b)  # [n, 1]\n",
    "        return self.__sampling(h_dist)  # [n, 1]\n",
    "\n",
    "    def __backward(self, h):\n",
    "        v_dist = self.sigmoid(np.matmul(self.weight, h) + self.a)  # [m, 1]\n",
    "        return self.__sampling(v_dist)  # [m, 1]\n",
    "\n",
    "    def __sampling(self, distribution):\n",
    "        dim = distribution.shape[0]\n",
    "        true_idx = np.random.uniform(0, 1, dim).reshape(dim, 1) <= distribution\n",
    "        sampled = np.zeros((dim, 1))\n",
    "        sampled[true_idx] = 1  # [n, 1]\n",
    "        return sampled\n",
    "\n",
    "    def __CD_1(self, v_n):\n",
    "        v_n = v_n.reshape(-1, 1)\n",
    "        h_sampled = self.__forward(v_n)\n",
    "        v_sampled = self.__backward(h_sampled)\n",
    "        h_recon = self.__forward(v_sampled)\n",
    "\n",
    "        self.weight += self.alpha * \\\n",
    "            (np.matmul(v_n, np.transpose(h_sampled)) -\n",
    "             np.matmul(v_sampled, np.transpose(h_recon)))\n",
    "        self.a += self.alpha * (v_n - v_sampled)\n",
    "        self.b += self.alpha * (h_sampled - h_recon)\n",
    "\n",
    "        self.energy_list.append(self._energy(v_n, h_recon))\n",
    "\n",
    "    def __contrastive_divergence(self, data, max_epoch):\n",
    "        train_time = []\n",
    "        for t in range(max_epoch):\n",
    "            np.random.shuffle(data)\n",
    "            self.energy_list = []\n",
    "\n",
    "            start = time.time()\n",
    "            pool = ThreadPool(5)\n",
    "            pool.map(self.__CD_1, data)\n",
    "            end = time.time()\n",
    "\n",
    "            avg_energy = np.mean(self.energy_list)\n",
    "            print(\"[epoch {}] takes {:.2f}s, average energy={}\".format(\n",
    "                t, end - start, avg_energy))\n",
    "            self.avg_energy_record.append(avg_energy)\n",
    "            train_time.append(end - start)\n",
    "        print(\"Average Training Time: {:.2f}\".format(np.mean(train_time)))\n",
    "\n",
    "    def _energy(self, visible, hidden):\n",
    "        return - np.inner(self.a.flatten(), visible.flatten()) - np.inner(self.b.flatten(), hidden.flatten()) \\\n",
    "            - np.matmul(np.matmul(visible.transpose(), self.weight), hidden)\n",
    "\n",
    "    def energy(self, v):\n",
    "        hidden = self.__forward(v)\n",
    "        return self._energy(v, hidden)\n",
    "\n",
    "    def __Gibbs_sampling(self, v_init, num_iter=10):\n",
    "        v_t = v_init.reshape(-1, 1)\n",
    "        for t in range(num_iter):\n",
    "            h_dist = self.sigmoid(\n",
    "                np.matmul(np.transpose(self.weight), v_t) + self.b)  # [n, 1]\n",
    "            h_t = self.__sampling(h_dist)  # [n, 1]\n",
    "\n",
    "            v_dist = self.sigmoid(\n",
    "                np.matmul(self.weight, h_t) + self.a)  # [m, 1]\n",
    "            v_t = self.__sampling(v_dist)  # [m, 1]\n",
    "\n",
    "        return v_t, h_t\n",
    "\n",
    "    def sample(self, num_iter=10, v_init=None):\n",
    "        \"\"\"Sample from trained model.\n",
    "        Args:\n",
    "            num_iter: int, the number of iterations used in Gibbs sampling\n",
    "            v_init: numpy ndarray of shape [m, 1], the initial visible units (default: None)\n",
    "        Return:\n",
    "            v: numpy ndarray of shape [m, 1], the visible units reconstructed from RBM.\n",
    "        \"\"\"\n",
    "        if v_init is None:\n",
    "            v_init = np.random.rand(self.m_visible, 1)\n",
    "        v, h = self.__Gibbs_sampling(v_init, num_iter)\n",
    "        return v\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.datasets.mnist' has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8d9ab855f95b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# load mnist dataset, no label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m  \u001b[1;31m# 60000x28x28\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mn_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mimg_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.datasets.mnist' has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# train restricted boltzmann machine using mnist dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load mnist dataset, no label\n",
    "    mnist = mnist  # 60000x28x28\n",
    "    n_imgs, n_rows, n_cols = mnist.shape\n",
    "    img_size = n_rows * n_cols\n",
    "    print(mnist.shape)\n",
    "\n",
    "    # construct rbm model\n",
    "    rbm = RBM(100, 28 * 28)\n",
    "\n",
    "    print(\"Start RBM training.\")\n",
    "    # train rbm model using mnist\n",
    "    rbm.train(mnist[:200], epochs=10)\n",
    "    print(\"Finish RBM training.\")\n",
    "\n",
    "    # sample from rbm model\n",
    "    v = rbm.sample(num_iter=200, v_init=mnist[0])\n",
    "    plt.imshow(v.reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 2), (150,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, 2:]  # Petal length and width\n",
    "y = iris.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/06/iris_tree.dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-286e59d8d0a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mclass_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mrounded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 filled=True)\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\tree\\_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m             \u001b[0mout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m             \u001b[0mown_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/06/iris_tree.dot'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(tree_clf, \n",
    "                out_file='models/06/iris_tree.dot', \n",
    "                feature_names=iris.feature_names[2:],\n",
    "                class_names=iris.target_names,\n",
    "                rounded=True,\n",
    "                filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'dot' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!dot -Tpng models/06/iris_tree.dot -o static/imgs/iris_tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
